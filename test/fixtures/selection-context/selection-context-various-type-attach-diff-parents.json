{
  "selectionType": "mixed",
  "items": {
    "parents": [],
    "children": [],
    "attachments": [
      {
        "item": {
          "id": 225,
          "key": "E9WVEIHL",
          "itemType": "attachment",
          "title": "Snapshot",
          "libraryID": 1,
          "parentItemID": 142,
          "data": {
            "key": "E9WVEIHL",
            "version": 5,
            "itemType": "attachment",
            "title": "Snapshot",
            "url": "http://arxiv.org/abs/2201.12329",
            "accessDate": "2026-01-03T14:43:32Z",
            "parentItem": "IY3FMWQM",
            "linkMode": "imported_url",
            "contentType": "text/html",
            "charset": "utf-8",
            "filename": "2201.html",
            "tags": [],
            "relations": {},
            "dateAdded": "2026-01-03T14:43:32Z",
            "dateModified": "2026-01-03T14:43:32Z",
            "path": "attachments/E9WVEIHL/Snapshot"
          }
        },
        "parent": {
          "id": 142,
          "key": "IY3FMWQM",
          "itemType": "preprint",
          "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR",
          "libraryID": 1,
          "parentItemID": null,
          "data": {
            "key": "IY3FMWQM",
            "version": 5,
            "itemType": "preprint",
            "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR",
            "abstractNote": "We present in this paper a novel query formulation using dynamic anchor boxes for DETR (DEtection TRansformer) and offer a deeper understanding of the role of queries in DETR. This new formulation directly uses box coordinates as queries in Transformer decoders and dynamically updates them layer-by-layer. Using box coordinates not only helps using explicit positional priors to improve the query-to-feature similarity and eliminate the slow training convergence issue in DETR, but also allows us to modulate the positional attention map using the box width and height information. Such a design makes it clear that queries in DETR can be implemented as performing soft ROI pooling layer-by-layer in a cascade manner. As a result, it leads to the best performance on MS-COCO benchmark among the DETR-like detection models under the same setting, e.g., AP 45.7\\% using ResNet50-DC5 as backbone trained in 50 epochs. We also conducted extensive experiments to confirm our analysis and verify the effectiveness of our methods. Code is available at \\url{https://github.com/SlongLiu/DAB-DETR}.",
            "date": "2022-03-30",
            "DOI": "10.48550/arXiv.2201.12329",
            "url": "http://arxiv.org/abs/2201.12329",
            "accessDate": "2026-01-03T14:43:30Z",
            "shortTitle": "DAB-DETR",
            "libraryCatalog": "arXiv.org",
            "extra": "arXiv:2201.12329 [cs]\nCitation Key: liu_dabdetr-dynamic_2022",
            "repository": "arXiv",
            "archiveID": "arXiv:2201.12329",
            "creators": [
              {
                "firstName": "Shilong",
                "lastName": "Liu",
                "creatorType": "author"
              },
              {
                "firstName": "Feng",
                "lastName": "Li",
                "creatorType": "author"
              },
              {
                "firstName": "Hao",
                "lastName": "Zhang",
                "creatorType": "author"
              },
              {
                "firstName": "Xiao",
                "lastName": "Yang",
                "creatorType": "author"
              },
              {
                "firstName": "Xianbiao",
                "lastName": "Qi",
                "creatorType": "author"
              },
              {
                "firstName": "Hang",
                "lastName": "Su",
                "creatorType": "author"
              },
              {
                "firstName": "Jun",
                "lastName": "Zhu",
                "creatorType": "author"
              },
              {
                "firstName": "Lei",
                "lastName": "Zhang",
                "creatorType": "author"
              }
            ],
            "tags": [
              {
                "tag": "Computer Science - Computer Vision and Pattern Recognition",
                "type": 1
              },
              {
                "tag": "match_status:unmatched"
              }
            ],
            "collections": [],
            "relations": {},
            "dateAdded": "2026-01-03T14:43:30Z",
            "dateModified": "2026-01-27T10:21:34Z"
          }
        },
        "filePath": "attachments/E9WVEIHL/Snapshot",
        "mimeType": null
      },
      {
        "item": {
          "id": 82,
          "key": "8VEUH6U2",
          "itemType": "attachment",
          "title": "Meng 等 - 2021 - Conditional DETR for Fast Training Convergence.md",
          "libraryID": 1,
          "parentItemID": 8,
          "data": {
            "key": "8VEUH6U2",
            "version": 0,
            "itemType": "attachment",
            "title": "Meng 等 - 2021 - Conditional DETR for Fast Training Convergence.md",
            "parentItem": "W4CDLU28",
            "linkMode": "linked_file",
            "contentType": "text/plain",
            "charset": "windows-1252",
            "path": "attachments/8VEUH6U2/Meng 等 - 2021 - Conditional DETR for Fast Training Convergence.md",
            "tags": [],
            "relations": {},
            "dateAdded": "2026-01-27T01:16:44Z",
            "dateModified": "2026-01-27T01:16:44Z"
          }
        },
        "parent": {
          "id": 8,
          "key": "W4CDLU28",
          "itemType": "conferencePaper",
          "title": "Conditional DETR for Fast Training Convergence",
          "libraryID": 1,
          "parentItemID": null,
          "data": {
            "key": "W4CDLU28",
            "version": 0,
            "itemType": "conferencePaper",
            "title": "Conditional DETR for Fast Training Convergence",
            "date": "2021",
            "url": "https://openaccess.thecvf.com/content/ICCV2021/html/Meng_Conditional_DETR_for_Fast_Training_Convergence_ICCV_2021_paper.html",
            "accessDate": "2026-01-27T00:49:31Z",
            "language": "en",
            "libraryCatalog": "openaccess.thecvf.com",
            "extra": "Citation Key: meng_conditional-detr_2021",
            "pages": "3651-3660",
            "conferenceName": "Proceedings of the IEEE/CVF International Conference on Computer Vision",
            "creators": [
              {
                "firstName": "Depu",
                "lastName": "Meng",
                "creatorType": "author"
              },
              {
                "firstName": "Xiaokang",
                "lastName": "Chen",
                "creatorType": "author"
              },
              {
                "firstName": "Zejia",
                "lastName": "Fan",
                "creatorType": "author"
              },
              {
                "firstName": "Gang",
                "lastName": "Zeng",
                "creatorType": "author"
              },
              {
                "firstName": "Houqiang",
                "lastName": "Li",
                "creatorType": "author"
              },
              {
                "firstName": "Yuhui",
                "lastName": "Yuan",
                "creatorType": "author"
              },
              {
                "firstName": "Lei",
                "lastName": "Sun",
                "creatorType": "author"
              },
              {
                "firstName": "Jingdong",
                "lastName": "Wang",
                "creatorType": "author"
              }
            ],
            "tags": [
              {
                "tag": "/unread",
                "type": 1
              }
            ],
            "collections": [],
            "relations": {},
            "dateAdded": "2026-01-27T00:49:31Z",
            "dateModified": "2026-01-27T10:22:49Z"
          }
        },
        "filePath": "attachments/8VEUH6U2/Meng 等 - 2021 - Conditional DETR for Fast Training Convergence.md",
        "mimeType": null
      },
      {
        "item": {
          "id": 10,
          "key": "A8BVFHT3",
          "itemType": "attachment",
          "title": "Meng 等 - 2021 - Conditional DETR for Fast Training Convergence.pdf",
          "libraryID": 1,
          "parentItemID": 8,
          "data": {
            "key": "A8BVFHT3",
            "version": 0,
            "itemType": "attachment",
            "title": "Meng 等 - 2021 - Conditional DETR for Fast Training Convergence.pdf",
            "url": "https://openaccess.thecvf.com/content/ICCV2021/papers/Meng_Conditional_DETR_for_Fast_Training_Convergence_ICCV_2021_paper.pdf",
            "accessDate": "2026-01-27T00:49:34Z",
            "parentItem": "W4CDLU28",
            "linkMode": "linked_file",
            "contentType": "application/pdf",
            "charset": "",
            "path": "attachments/A8BVFHT3/Meng 等 - 2021 - Conditional DETR for Fast Training Convergence.pdf",
            "tags": [],
            "relations": {},
            "dateAdded": "2026-01-27T00:49:34Z",
            "dateModified": "2026-01-27T00:49:34Z"
          }
        },
        "parent": {
          "id": 8,
          "key": "W4CDLU28",
          "itemType": "conferencePaper",
          "title": "Conditional DETR for Fast Training Convergence",
          "libraryID": 1,
          "parentItemID": null,
          "data": {
            "key": "W4CDLU28",
            "version": 0,
            "itemType": "conferencePaper",
            "title": "Conditional DETR for Fast Training Convergence",
            "date": "2021",
            "url": "https://openaccess.thecvf.com/content/ICCV2021/html/Meng_Conditional_DETR_for_Fast_Training_Convergence_ICCV_2021_paper.html",
            "accessDate": "2026-01-27T00:49:31Z",
            "language": "en",
            "libraryCatalog": "openaccess.thecvf.com",
            "extra": "Citation Key: meng_conditional-detr_2021",
            "pages": "3651-3660",
            "conferenceName": "Proceedings of the IEEE/CVF International Conference on Computer Vision",
            "creators": [
              {
                "firstName": "Depu",
                "lastName": "Meng",
                "creatorType": "author"
              },
              {
                "firstName": "Xiaokang",
                "lastName": "Chen",
                "creatorType": "author"
              },
              {
                "firstName": "Zejia",
                "lastName": "Fan",
                "creatorType": "author"
              },
              {
                "firstName": "Gang",
                "lastName": "Zeng",
                "creatorType": "author"
              },
              {
                "firstName": "Houqiang",
                "lastName": "Li",
                "creatorType": "author"
              },
              {
                "firstName": "Yuhui",
                "lastName": "Yuan",
                "creatorType": "author"
              },
              {
                "firstName": "Lei",
                "lastName": "Sun",
                "creatorType": "author"
              },
              {
                "firstName": "Jingdong",
                "lastName": "Wang",
                "creatorType": "author"
              }
            ],
            "tags": [
              {
                "tag": "/unread",
                "type": 1
              }
            ],
            "collections": [],
            "relations": {},
            "dateAdded": "2026-01-27T00:49:31Z",
            "dateModified": "2026-01-27T10:22:49Z"
          }
        },
        "filePath": "attachments/A8BVFHT3/Meng 等 - 2021 - Conditional DETR for Fast Training Convergence.pdf",
        "mimeType": null
      }
    ],
    "notes": [
      {
        "item": {
          "id": 227,
          "key": "L7UH9D4Y",
          "itemType": "note",
          "title": "Comment: Accepted to ICLR 2022",
          "libraryID": 1,
          "parentItemID": 142,
          "data": {
            "key": "L7UH9D4Y",
            "version": 5,
            "itemType": "note",
            "parentItem": "IY3FMWQM",
            "note": "Comment: Accepted to ICLR 2022",
            "tags": [],
            "relations": {},
            "dateAdded": "2026-01-03T14:43:30Z",
            "dateModified": "2026-01-03T14:43:30Z"
          }
        },
        "parent": {
          "id": 142,
          "key": "IY3FMWQM",
          "itemType": "preprint",
          "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR",
          "libraryID": 1,
          "parentItemID": null,
          "data": {
            "key": "IY3FMWQM",
            "version": 5,
            "itemType": "preprint",
            "title": "DAB-DETR: Dynamic Anchor Boxes are Better Queries for DETR",
            "abstractNote": "We present in this paper a novel query formulation using dynamic anchor boxes for DETR (DEtection TRansformer) and offer a deeper understanding of the role of queries in DETR. This new formulation directly uses box coordinates as queries in Transformer decoders and dynamically updates them layer-by-layer. Using box coordinates not only helps using explicit positional priors to improve the query-to-feature similarity and eliminate the slow training convergence issue in DETR, but also allows us to modulate the positional attention map using the box width and height information. Such a design makes it clear that queries in DETR can be implemented as performing soft ROI pooling layer-by-layer in a cascade manner. As a result, it leads to the best performance on MS-COCO benchmark among the DETR-like detection models under the same setting, e.g., AP 45.7\\% using ResNet50-DC5 as backbone trained in 50 epochs. We also conducted extensive experiments to confirm our analysis and verify the effectiveness of our methods. Code is available at \\url{https://github.com/SlongLiu/DAB-DETR}.",
            "date": "2022-03-30",
            "DOI": "10.48550/arXiv.2201.12329",
            "url": "http://arxiv.org/abs/2201.12329",
            "accessDate": "2026-01-03T14:43:30Z",
            "shortTitle": "DAB-DETR",
            "libraryCatalog": "arXiv.org",
            "extra": "arXiv:2201.12329 [cs]\nCitation Key: liu_dabdetr-dynamic_2022",
            "repository": "arXiv",
            "archiveID": "arXiv:2201.12329",
            "creators": [
              {
                "firstName": "Shilong",
                "lastName": "Liu",
                "creatorType": "author"
              },
              {
                "firstName": "Feng",
                "lastName": "Li",
                "creatorType": "author"
              },
              {
                "firstName": "Hao",
                "lastName": "Zhang",
                "creatorType": "author"
              },
              {
                "firstName": "Xiao",
                "lastName": "Yang",
                "creatorType": "author"
              },
              {
                "firstName": "Xianbiao",
                "lastName": "Qi",
                "creatorType": "author"
              },
              {
                "firstName": "Hang",
                "lastName": "Su",
                "creatorType": "author"
              },
              {
                "firstName": "Jun",
                "lastName": "Zhu",
                "creatorType": "author"
              },
              {
                "firstName": "Lei",
                "lastName": "Zhang",
                "creatorType": "author"
              }
            ],
            "tags": [
              {
                "tag": "Computer Science - Computer Vision and Pattern Recognition",
                "type": 1
              },
              {
                "tag": "match_status:unmatched"
              }
            ],
            "collections": [],
            "relations": {},
            "dateAdded": "2026-01-03T14:43:30Z",
            "dateModified": "2026-01-27T10:21:34Z"
          }
        },
        "tags": [],
        "collections": []
      }
    ]
  },
  "summary": {
    "parentCount": 0,
    "childCount": 0,
    "attachmentCount": 3,
    "noteCount": 1
  },
  "warnings": [],
  "sampledAt": "2026-01-27T11:37:43.034Z"
}
